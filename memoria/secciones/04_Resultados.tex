\chapter{Results}

In this chapter we will show the results obtained in this work. They will be divided between the three metrics we chose to monitor (see section Experiment Design in the Development chapter).

\section{Rasterization Baseline}
First of all and as a sanity check, we will compare the performance of a renderer using ray tracing to one drawing the same geometry through rasterization. The model chosen for this will be the Viking Room from the Vulkan Tutorial \cite{VulkanTutorial}.

In the first place we will look at how video memory usage changes as the frame sizes get bigger. We can see a comparison of how much memory both renderers employ in graph \ref{memory-usage-comparison-graph}. We see an expected increase in memory consumption as the frame buffer resolutions get bigger, as well as a huge difference, of about an order of magnitude, between the two methods for any given resolution. This is to be expected not only because a bigger frame buffer will require more memory to be stored, but also because the ray tracer requires to store an acceleration structure as well as all the possible shaders bound at the same time.

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=1.0\textwidth]{figuras/vulkan-memory-usage-comparison.png}
    \caption{GPU memory consumption when rendering the Viking Room 3D model at a range of reasonable resolutions, using ray traced and traditionally rasterized graphics. We can see a significant difference between the two, as well as an expected increase as resolutions get higher.}
    \label{memory-usage-comparison-graph}
\end{figure}

Rasterized renderers have an initialization process quite different than raytraced ones since they do not make use of an acceleration structure. Therefore, we cannot compare it's building time in this context.

To finish this part, we will compare frame times from both renderers in the same fashion as the memory usage one: with the same model (Viking Room), we'll run them for 1000 frames and take the average time it took to render them at different screen resolutions. We can see how they stack up in figure \ref{frametimes-comparison-graph}. This is very similar to the memory usage comparison in that both frame times increase as the frame buffer resolution grows, with the rasterized renderer finishing the job much quicker than it's counterpart. In any case, in this instance the performance difference is even more exaggerated between the two, with rasterized graphics greatly surpassing ray traced ones.

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=1.0\textwidth]{figuras/vulkan-frametimes-comparison.png}
    \caption{Single frame rendering time when drawing the Viking Room 3D model at a range of reasonable resolution, using ray traced and traditionally rasterized graphics. As with the memory consumption graph, we see how the two of them take longer to finish in higher resolutions, while the rasterized renderer greatly outperforms the ray traced one.}
    \label{frametimes-comparison-graph}
\end{figure}

\section{Memory Usage}
To start the real comparison between Vulkan and OptiX we will look at the memory usage in GPU across both libraries, all models and all resolutions. We can see how much each model consumes in graph \ref{memory-usage-raytraced-comparison-graph}.

This is the first example of a trend we will start seeing throughout this chapter. Vulkan, either despite or thanks to it's explicitness when developing applications, is able to load and render the same ammount of geometry and detail as OptiX while requiring only a fraction of the resources, in this case video memory. This remains true while increasing the frame buffer size, with both libraries increasing the required memory at a similar rate. One last remarkable thing is the Hairball test case. Here we see the memory consumption for both libraries is very similar, which suggests the two technologies tend to use a similar ammount of resources when triangle counts tend to infinity.

\begin{figure}
    \subfloat[BMW]{\includegraphics[width = 3in]{figuras/bmw-memory-usage-comparison.png}}
    \subfloat[Sponza]{\includegraphics[width = 3in]{figuras/sponza-memory-usage-comparison.png}}\\
    \centering
    \subfloat[Hairball]{\includegraphics[width = 3in]{figuras/hairball-memory-usage-comparison.png}}
    \caption{Memory consumption of OptiX and Vulkan (raytraced) when rendering the 3D models BMW, Sponza and Hairball.}
    \label{memory-usage-raytraced-comparison-graph}
\end{figure}

\clearpage
\section{Acceleration Structure Build Time}
Next up we will be looking at the Acceleration Structure Build time across both libraries. Although in our experiments this was only done once per program execution, applications that perform animations or other form of dynamic geometry may need to partly rebuild their AS as frequent as once per frame. Thus, the time it takes to do so (although not all of it) could be counting towards the total time it takes to process a full application cycle (along with rendering, and simulation, etc.).

If we plot the Acceleration Structure Building Times in the same way as we did with the memory consumption, we get the graphs at figure \ref{as-build-time-comparison-graph}.

\begin{figure}
    \subfloat[BMW]{\includegraphics[width = 3in]{figuras/bmw-acceleration-structure-build-time-comparison.png}}
    \subfloat[Sponza]{\includegraphics[width = 3in]{figuras/sponza-acceleration-structure-build-time-comparison.png}}\\
    \centering
    \subfloat[Hairball]{\includegraphics[width = 3in]{figuras/hairball-acceleration-structure-build-time-comparison.png}}
    \caption{Acceleration Structure Build Time of OptiX and Vulkan (raytraced) when rendering the 3D models BMW, Sponza and Hairball. Sorted by rendering resolution.}
    \label{as-build-time-comparison-graph}
\end{figure}

We can plainly see how the rendering resolution does not affect the accel build time. This is to be expected, since a higher pixel count works with the same Acceleration Structure as a lower pixel count. We will now rearrange the plots in figure \ref{as-build-time-geometry-comparison-graph} to see how geometry ammount affects acceleration structure build times.

A curious phenomenon is shown here. We initially expected the Hairball model to have the greatest acceleration structure build time. This is true for Vulkan where the triangle count is directly proportional to the build time. In OptiX however, the first spot is granted to Sponza, with about 10 times less triangles than the Hairball. This could be due to this model having a wider variety of shapes formed by it's triangles, which could be harder to optimize, as opposed to the hairball, where everything is more similar and packed together.

When comparing both libraries, even in the most discrepant case (Hairball), we see Vulkan being at least slightly faster, around a 20\% on average across all cases and in most of them simply a lot faster than OptiX when building the AS.

\begin{figure}
    \subfloat[1280x720]{\includegraphics[width = 3in]{figuras/1280x720-acceleration-structure-geometry-build-time-comparison.png}}
    \subfloat[1920x1080]{\includegraphics[width = 3in]{figuras/1920x1080-acceleration-structure-geometry-build-time-comparison.png}}\\
    \subfloat[2560x1440]{\includegraphics[width = 3in]{figuras/2560x1440-acceleration-structure-geometry-build-time-comparison.png}}
    \subfloat[3840x2160]{\includegraphics[width = 3in]{figuras/3840x2160-acceleration-structure-geometry-build-time-comparison.png}}
    \caption{Acceleration Structure Build Time of OptiX and Vulkan (raytraced) when rendering the 3D models BMW, Sponza and Hairball. Sorted by model.}
    \label{as-build-time-geometry-comparison-graph}
\end{figure}

To further investigate why Sponza takes that much longer to build than other models, we first timed each part of the building process separately. We see this in figure \ref{as-build-time-decomposed}. We observe how the distribution of times for each model is completely different. The Hairball model takes the longest by far to build it's TLAS, while Sponza takes it's much longer time mostly building the Bottom Level part, taking as little as the BMW one in the Top Level stage.

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=1.0\textwidth]{figuras/optix-accelbuildtimes-decomposed.png}
    \caption{Acceleration Structure Build Times for each model, divided between the TLAS and BLAS phases. We see great discrepancies in the distribution of time in each case.}
    \label{as-build-time-decomposed}
\end{figure}
\clearpage
\section{Frame Time}
Finally we will look at how long each technology takes to render a full frame. This could be considered the most important metric to monitor, since rendering a frame is something that will happen as often as possible, and therefore the ammount of time it takes to do so will be more prevalent than updating or initializing geometry structures.

As mentioned before, each frame will be rendered to a frame buffer and we will only count the time it takes to do exactly that, although we will then display them in a window so we can see what the renderer is doing.

In a modern operating system, the time it takes to perform a certain task can vary a lot depending on what other processes are running at the time. To counteract this, we timed the render of 1000 frames for each parameter combination and averaged them. An example of that can be seen in figure \ref{frametimes-outlier-graph}.

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=1.0\textwidth]{figuras/frametime-outlier.png}
    \caption{Time taken for rendering 1000 frames when drawing the BMW 3D model at 1280x720, using ray tracing. We see how the first frame takes much longer than the rest of them to draw.}
    \label{frametimes-outlier-graph}
\end{figure}

We decided to remove the first frame time from this average since, as you can see, it tends to be a statistical outlier, messing with "real world" appreciable results. The same graph from \ref{frametimes-outlier} results thus in \ref{frametimes-no-outlier}.

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=1.0\textwidth]{figuras/frametime-no-outlier.png}
    \caption{Time taken for rendering 1000 frames when drawing the BMW 3D model at 1280x720, using ray tracing. We have removed the first frame time since it took too long to draw in comparison with the rest.}
    \label{frametimes-no-outlier-graph}
\end{figure}

With this preprocessing in place, we will first look at an overview for all models and resolutions in figure \ref{frametimes-overview-graph}. For the most part the graphs show what one might expect: render times get larger as screen resolution increases, with OptiX taking the longest across all cases. There is however a slightly odd yet expected behaviour. As we see, the model taking the longer to draw in both libraries is Sponza. The much bigger Hairball shows times more similar to the BMW model, with about 10 times more geometry. This suggests that complexity in shapes and textures may be more costly to render than a higher triangle count. 

This discrepancy between triangle count and processing time reminds to the Acceleration Structure Build Times, where OptiX also struggled the most to optimize the Sponza geometry compared to the others. The main difference is here both libraries have the most trouble to draw this particular scene.

\begin{figure}
    \subfloat[BMW]{\includegraphics[width = 3in]{figuras/bmw-frametimes-comparison.png}}
    \subfloat[Sponza]{\includegraphics[width = 3in]{figuras/sponza-frametimes-comparison.png}}\\
    \centering
    \subfloat[Hairball]{\includegraphics[width = 3in]{figuras/hairball-frametimes-comparison.png}}
    \caption{Frame rendering times for each 3D model (BMW, Hairball and Sponza) across both libraries and 4 reasonable resolutions, from 720p to 4k.}
    \label{frametimes-overview-graph}
\end{figure}

\section{Hardware comparison}
As mentioned in the Development chapter, we will now run our software in all the machines we could gather from friends, family and fellow students. This will help us gauge how the same workload is handled by different GPUs, how CPUs affect performance while maintaining the same GPU and even how both libraries behave inside a virtual machine.
